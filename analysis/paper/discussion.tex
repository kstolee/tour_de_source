\section{Discussion}
\label{sec:discussion}

In this section, we discuss the implications of these empirical findings on tool designers and users of regex tools and opportunities for future work.

\subsection{Implications For Tool Designers}

We observe that, although the clusters were generated based on behavioral similarity, they are often centered around the presence of certain features. Thus, omitting those features in a tool's implementation often omits an entire space of regular expression behaviors.

\subsubsection{STR, END}
The endpoint anchor features STR and END are useful for specifying how a pattern relates to the beginning or end of a line, or an entire line from beginning to end.  In our survey, over half (56\%) of the respondents answers that they use endpoint anchors frequently or very frequently, and none of them claimed to never use them.  Some common use cases require the endpoint anchors, such as specifying that some content is first or last in an input.  In multi-line mode, endpoint anchors match the beginning and ending of each line.  For example the regex \verb!(?m)^\s*$! will match every line that is only whitespace.

From Table~\ref{table:featureStats} we know that STR and END features are present in over half of the scanned projects containing utilizations - further evidence of the importance of these features.  The brics library does not support this feature, which is a missed opportunity for many developers who could otherwise have used brics to model their regexes that use STR and END.

\subsubsection{LZY}
The LZY feature modifies the behavior of the repetition features (i.e., ADD, KLE, QST, DBB, LWB, SNG) by forcing them to use as few repetitions as possible for a match.  The default behavior for the repetition features is to use as many repetitions as possible for a match.  Consider trying to find the shortest sequence of binary characters starting and ending with a 1 within the binary sequence: {\tt 1010001}. The pattern \verb!`1.*1'! will match the entire sequence whereas the pattern \verb!`1.*?1'! will match {\tt 101} because the KLE repetition feature was modified by the LZY feature.  There is no way to obtain shortest matches without the LZY feature.  LZY is present in over 36\% of scanned projects with utilizations (see Table~\ref{table:featureStats}), and yet was not supported by two of the four major regex projects we looked at.
In our developer survey, 11\% (2) of participants use this feature frequently and 6 (33\%) use it occasionally, showing a modest impact on potential users.

\subsubsection{PNG and BKRN vs CG and BKR}
The PNG group (python-style named capture groups) and BKRN (back-references: named) are intended to operate together to allow users to name the content that is expected to appear in a capture group.  A simple example of how these can be used together with the named capture group matching some vowel is:
\verb!(?P<vowel>[aeiou]x(?P=vowel))! which will match the strings 'axa' and 'oxo' but not 'txt'.  The same functionality can be obtained with a much shorter expression: \verb!([aeiou])x\1! where the \verb!'\1'! references the CG started by the first left parenthesis found when moving from left to right.  When survey participants were asked if they prefer to always use numbered capture groups, alway s use named captured groups or 'it depends', 66\% (12) of survey participants said that they always use BKR, and the remaining 33\% (6) said `it depends'.  No one said that they always use named capture groups, and the participants who answered 'it depends' said that they would only use named capture groups when composing a very large regex.  BKR is present in 5\% of scanned projects, while BKRN is present in only 1.7\%, which corroborates our findings that numbered capture groups are generally preferred over named capture groups.

\subsection{Key User Behaviors to Support}
Here we offer a discussion of the main behaviors that are important for tool designers to support.

\subsubsection{Capturing Specific Content}
The survey results from section~\ref{sec:survey} indicated that capturing parts of strings was the second most frequent activity that developers used regex for.  As mentioned in section~\ref{sec:featureUsage}, the CG feature is the most frequently used feature in terms of patterns (see Table~\ref{table:featureStats}).  As mentioned in Section~\ref{sec:clusterResults}, capturing values assigned to variables when parsing source code was one of the main categories of clusters observed.  The ability to capture some part of a match provides a powerful tool to programmers.  The CG feature has two functions: 1. it allows logical grouping as would be expected by parenthesis, and 2. it allows retrieval of information that was in one logical grouping.  Although the four regex projects all support the very necessary logical grouping aspect of the feature, none support the BKR feature that retrieves what content was found in an earlier CG.  Any non-trivial tool or research that hopes to be applicable to regex use in practice must treat the CG feature as especially important, and must support some way to reason about what information is retrieved by capture groups.

\subsubsection{Counting Delimiters and Finding Flags}
Text files containing one unit of information per line are common in a wide variety of applications (for example log and csv files).  Out of the 13,912 patterns in the corpus, 3444 (24\%) contained ANY followed by KLE: \verb!`.*'!, often at the end of the pattern.
One reasonable explanation for this tendency to put \verb!`.*'! at the end of a pattern is that users want to disregard all matches after the first match on a single line in order to count how many distinct lines the match occurs on.  Survey participants indicated an average frequency of 'Counting lines that match a pattern' and 'Counting substrings that match a pattern' at 3.2 or Rarely/Occasionally.

Delimiters that separate items on one line like \verb!','! are also quite common.  Although survey participants indicated an average frequency of 1.7 (very rarely or never) for 'checking for a single character', we found 19 clusters whose essential behavior was to search for one or two characters.  This makes sense if you consider that the top ranked activity for developers was 'Locating content within a file or files', and usually this content is located using some small set of characters that the user knows will flag that content.  Looking closely at that category of cluster, some of the characters being searched for were \verb!-!, \verb!#! and \verb!:! - all common delimiters in different scenarios.

\subsection{Opportunities For Future Work}

Based on our findings, there are many opportunities for future work.

\subsubsection{A Modern WRD Character Class}
One surprising result of our clustering is that, behaviorally speaking, the negation of the word class NWRD was used in 208 projects, while the word class itself was used in only 114 projects. After inspecting several projects using the patterns found in this behavioral cluster, we concluded that most users are trying to sanitize arbitrary strings that must conform to a system character set requirement, such as requirements for filenames.  For example, a user might replace all NWRD matching characters with the `\_' to guarantee that an arbitrary string can be used as a filename.  We also considered the largest cluster using custom character classes (\verb?`[^ -~]'(122)?) and concluded that users are constructing a more permissive version of the NWRD character class, to allow more non-letter, non-digit characters than just the `\_' in their sanitized strings.  More research is needed to determine if a more modern WRD class could be useful, and if so, what characters set is preferred.

\subsubsection{Refactoring Regex for Readability}
The survey showed that users want readability and find the lack of readable regexes to be a major pain point.  Certain character classes that are logically equivalent can be expressed differently.  One avenue for future exploration is a tool to transform a regex with an character class that is difficult to read into one that has the same effect but is easier to understand.
Other similar refactoring techniques may become evident with a more thorough search.  A tool that preserved the exact behavior of a regex but optimized for readability could be incorporated into an IDE and relieve some developer pain.  More research is needed into why certain character classes are considered more readable, as has been done for other refactoring work (e.g.,~\cite{StoleeTSE2013}).
Similarly, there are several principals that can be followed to enhance the performance of a regex.  Using non-capture groups whenever possible, avoiding backtracking, etc.  In theory it seems possible to build a compiler that could compose a regex with identical behavior but with better readability and performance.

\todoMid{talk about performance and cite Chris}
\subsubsection{Developer Awareness of Best Practices}
One category of 5 clusters in the top 100 contained regex patterns to parse the contents of angle brackets.  Because the contents of angle brackets are usually unconstrained, regex are a poor replacement for XML or HTML parsers.  Using regex instead of a parser can lead to many programming disasters, as thoroughly discussed on the StackOverflow page dedicated to this topic\footnote{\url{http://stackoverflow.com/questions/1732348}}.  More research is needed into how regex users discover best practices and how aware they are of how regexes should and should not be used.

\subsubsection{Library Support for Developers}
Within standard programming languages, regular expressions libraries are very common, yet there are  differences between languages in the features that they support. For example, Java supports possessive quantifiers like \verb! `ab*+c'! (here the `+' is modifying the `*' to make it possessive) whereas Python does not. Such differences among programming language implementations was identified as a pain point for using regular expressions by 17\% of the survey participants. \todoMid{"so what?"} 


\subsubsection{Automated Regex Repair}
Given a suite of tests and a high suspiciousness score for lines of code containing regex, an automated system could searh for similar regexes to try in place of the faulty one.  The same clustering technique that we used to study regex behavior could be used to index groups of similar regexes, speeding up the process of searching for a replacement.
\todoMid{Katie do this}



