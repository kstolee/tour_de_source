\section{Discussion}
\label{sec:discussion}

In this section, we discuss the implications of these empirical findings 
%on tool designers and users of regex tools
 and opportunities for future work.

\subsection{Implications For Tool Designers}
The results in this work have several implications for tool designers who want to effectively support developers who use regular expressions.

\subsubsection{Developer Preferences Vary Considerably}
Often, equivalent regexes can be built using different language features. In the case of CCC versus default character classes (Table~\ref{tab:cccvsdefault}), developers are roughly evenly split in their preferences, indicating that tool builders should support both ways of doing things to enable as many developers as possible. \todoMid{can we come up with an example that's not well supported by existing tools?}

\subsubsection{Capturing Specific Content}
The survey results from Section~\ref{rq1:survey} indicate that capturing parts of strings is among the most frequent activities for which developers use regexes.
Looking at this from a feature perspective, the capture group (CG) is the most frequently used in terms of patterns (Table~\ref{table:featureStats}).  This feature has two functions: 1) it allows logical grouping as would be expected by parenthesis, and 2) it allows retrieval of information in one logical grouping.  As mentioned in Section~\ref{rq4:results}, capturing content was a primary goal evident in several categories of cluster, in particular, the fourth-largest cluster will capture the content between brackets or parentheses (Section~\ref{cluster:contentparens}).  Thus, we observe that the ability to capture some part of a match provides a powerful tool to programmers. 

\todoMid{In my experience, I have used capture groups in the find and replace functionality of a text editor to transform large, well-structured documents in many steps.  I have also used them in java programs to get the critical data from some predictable text (like part of a number).  Then I have also used them in shell scripts in a similar way - to pass the captured content into a program.  It's worth noting the prevalence of }
\verb!(.*)!
\todoMid{ also - capturing everything around some markers like }
\verb!(.*)\\(.*\\)!
\todoMid{  or }
\verb!(.*){(.*)}(.*)!
\todoMid{  or}
 \verb!\\[(.*)\\]!.
 \todoMid{ I think it's hard for a reader of our paper to understand this trend without seeing the large number of similar-themed actual regexes, and then our findings feel a little flat because of course capture groups are used to get information...  At the same time, I think it's important to recognize that about half of the patterns I've seen could not be expressed without using CG to specify logical groups for repetition or as the end of any abstraction expressed using other features.  One very interesting question for future research is how to tell when regexes are using CG for just capturing, just grouping or both.  We do not have an approach but it's a point to be explored.}

This feature is well supported by existing tools, but this provides evidence that future tools must treat the CG feature as especially important, and must support some way to reason about what information is retrieved by capture groups.

\subsubsection{Finding Specific Content}
Two categorical clusters, \emph{Specific Characters Must Match} (Section~\ref{cluster:single}) and \emph{Two or More Characters in Sequence} (Section~\ref{cluster:multiple}), deal with identifying the presence of specific character(s). While multiple character matching subsumes single character matching, the overarching theme  is that these regexes are looking to validate strings based on the presence of very specific content, as would be done for many common activities listed in Table~\ref{tab:regexactivities}, such as parsing user input. (This is in contract to \emph{capturing} specific content, as \emph{finding} deals with string validation and \emph{capturing} deals with string extraction.) 

%As indicated by the clusters of specific character matches in Section~\ref{cluster:single}, finding specific content is important.
%Delimiters that separate items on one line like \verb!`\t'! are also quite common.  
%Although survey participants indicated an average frequency of 1.7 (very rarely or never) for ``checking for a single character," we found that 17 of the top 100 clusters revolved around the presence of a single character.
The commonality of regexes related to finding content is consistent with the top ranked activity for developers, ``Locating content within a file or files." 
%and usually this content is located using some small set of characters that the user knows will flag that content.  
Looking closely at the \emph{Specific Character Must Match} cluster, some of the characters being searched for were \verb!\n!, \verb!-! and \verb!.!, which are all common delimiters in different scenarios. Combined with the cluster on \emph{Code Search and Variable Capturing} (Section~\ref{cluster:search}), this emphasizes the need for regex tools to  facilitate easy file parsing, or for a tool to include built-in support for specific types of parsing, such as finding a twitter handle (i.e., \verb!@[a-z]+!) or a version number, (i.e., \verb!v[0-9]+.*!), both of which are appear in these clusters. 
\todoMid{Can we make the following statement? Presumably, the developer may also want to capture specific content, such as the actual twitter handle or the actual version number, but may not know how to do that with regex libraries and may rely on string parsing instead.}

%\todoMid{The main difference between the Specific Character Must Match group and the multiple characters must match is that the first can subsume the second.  I think it's important to defend this and expose that we understand that our simplification of clusters to their shortest representative combined with the behavioral clustering technique will drastically over-emphasize similarities revolving around single characters, so instead of listing this as a major group, or a major finding, we may need to admit that it is an emphasis that our technique introduces artificially.  I think that in practice, the patterns being searched for usually revolve around more than just a single character, although maybe not a lot more than that.  I think it is more telling that despite our technique's tendency to over-cluster things around a single character, there was still an entire category that required two or more characters, and so those specific pairs or triples or whatever in that cluster are extremely key character combinations.  Let's see a few of those that seem to make sense: }
%\verb! {2,}!
%\todoMid{ :two or more spaces, }
%\verb!@[a-z]+!
%\todoMid{ :a lowercase twitter handle or similar,}
% \verb!\\$[()]!
% \todoMid{ :a dollar followed by either paren, }
% \verb!v[0-9]+.*!
% \todoMid{ :the letter `v' followed by some numbers, perhaps a version number.  }

\subsubsection{Counting Lines}
Text files containing one unit of information per line are common in a wide variety of applications (for example .log and .csv files).  Out of the 13,912 patterns in the corpus, 3,444 (24\%) contained ANY followed by KLE  (i.e., \verb!`.*'!), often at the end of the pattern.
One reasonable explanation for this tendency to put \verb!`.*'! at the end of a pattern is that users want to disregard all matches after the first match on a single line in order to count how many distinct lines the match occurs on.  Survey participants indicated an average frequency of ``Counting lines that match a pattern" and ``Counting substrings that match a pattern" at 3.2 or rarely/occasionally. It may be valuable for tool builders to include support for common activities such as line counting. 



%\todoMid{In a completely unrelated train of thought, I have been considering how regexes are one major way, and perhaps the only practical way in the world of computer science to handle the invisible characters like ASCII 0-32.  That's 33 characters like `backspace' and `end of medium' and 'vertical tab' that can appear in text and cause problems.  I've heard them called `Gremlins'.  So what do people do?  They write regexes to clean those out.}



\subsection{Opportunities For Future Work}

There are many opportunities for future work. \todoLast{Hey Kids! Need a thesis topic? Here's a bunch! Promote this awesome section earlier}




\subsubsection{Refactoring Regexes}
The survey showed that users want readability and find the lack of readable regexes to be a major pain point.
This provides an opportunity to introduce refactoring transformations to enhance readability.
As one opportunity, certain character classes that are logically equivalent can be expressed differently, for example, \verb!\d! $\equiv$ \verb![0123456789]! $\equiv$ \verb![0-9]!. While \verb!\d! is more succinct, \verb![0-9]! may be easier to read, so a refactoring for \emph{default to custom character classes} could be introduced.
Human studies are needed to evaluate the readability of various regex features in order to define and support appropriate regex refactorings for readability.

Another avenue of refactoring could be for performance. Various implementations of regex libraries may perform more efficiently with some features than others. An evaluation of regex feature implementation speeds would facilitate semantic transformations based on performance, similar to performance refactorings for LabVIEW~\cite{chambers2013smell, chambers2015impact}.

%Other similar refactoring techniques may become evident with a more thorough search.  A tool that preserved the exact behavior of a regex but optimized for readability could be incorporated into an IDE and relieve some developer pain.  More research is needed into why certain character classes are considered more readable, as has been done for other refactoring work (e.g.,~\cite{StoleeTSE2013}).
%Similarly, there are several principals that can be followed to enhance the performance of a regex.  Using non-capture groups whenever possible, avoiding backtracking, etc.  In theory it seems possible to build a compiler that could compose a regex with identical behavior but with better readability and performance.


\subsubsection{Developer Awareness of Best Practices}
One category of 10 clusters in the top 100 contained regex patterns, \emph{Content of Brackets and Parenthesis}, parses the contents of angle brackets.  As the contents of angle brackets are usually unconstrained, regexes are a poor replacement for XML or HTML parsers.  This may be a missed opportunity for the regex users to take advantage of more robust tools. More research is needed into how regex users discover best practices and how aware they are of how regexes should and should not be used.
%http://english.stackexchange.com/questions/50851/the-contents-are-or-the-contents-is

\subsubsection{Migration  Support for Developers}
Within standard programming languages, regular expressions libraries are very common, yet there are  differences between languages in the features that they support. For example, Java supports possessive quantifiers like \verb! `ab*+c'! (here the `+' is modifying the `*' to make it possessive) whereas Python does not. Differences among programming language implementations was identified as a pain point for using regular expressions by 17\% of the survey participants. This provides an opportunity for future work that makes such differences between languages explicit or for new libraries that translate between regex utilizations in various languages.

%\subsubsection{Support for Regexes Composition}
%According to our survey, over 60\% of developers find regexes to be difficult to compose. Additionally, developers frequently or very frequently write tests for their regexes. This provides an opportunity to instead

\subsubsection{Automated Regex Repair}
Regular expression errors are common and have produced thousands of bug reports~\cite{Spishak:2012:TSR:2318202.2318207}. This provides an opportunity to introduce automated repair techniques to fix.
Recent approaches to automated program repair rely on mutation operators to make small changes to source code and then re-run the test suite (e.g., ~\cite{cacm10, genprog-tse-journal}). In regular expressions, it is likely that the broken regex is close, semantically, to the desired regex. Syntax changes can lead to big changes in behavior, so we hypothesize that using the semantic clusters identified in Section~\ref{rq4:results} to identify potential repair candidates could efficiently and effectively converge on a repair candidate.


\subsubsection{Tool-Specific Regex Exploration}
In some environments, such as command line or text editor, regexes are used extensively (Section~\ref{rq1:survey}), but these regular expressions do not persist. Thus, using a repository analysis for feature usage only illustrates part of how regexes are used in practice. Exploring how the feature usage differs between environments would help inform tool developers about how to best support regex usage in context, and is left for future work.


% \subsubsection{A Modern WRD Character Class}
% \todoMid{update}
% One unexpected result of our clustering is that, behaviorally speaking, the negation of the word class NWRD was used in 208 projects, while the word class itself was used in only 114 projects. After inspecting several projects using the patterns found in this behavioral cluster, we concluded that most users are trying to sanitize arbitrary strings that must conform to a system character set requirement, such as requirements for filenames.  For example, a user might replace all NWRD matching characters with the `\_' to guarantee that an arbitrary string can be used as a filename.  We also considered the largest cluster using custom character classes (\verb?`[^ -~]'(122)?) and concluded that users are constructing a more permissive version of the NWRD character class, to allow more non-letter, non-digit characters than just the `\_' in their sanitized strings.  More research is needed to determine if a more modern WRD class could be useful, and if so, what characters set is preferred.


