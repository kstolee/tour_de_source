\section{Study}
\label{sec:study}
% \subsection{\centerline{DEFINITIONS}}

% \begin{center}
% \begin{tabular}
% {lcc}
% term & meaning & example  \\
% \toprule
% pattern & a composition of regex tokens & 'ab*c' \\
% \midrule
% usage & distinct function, pattern and flags within one filepath of one project & re.compile('ab*c') \\
% \midrule
% \end{tabular}
% \end{center}

To understand how programmers use regular expressions in Python projects and the syntactic and semantic diversity among the regular expressions, we scraped X projects from GitHub, as described in Section~\ref{study:corpus}. Next, we logged all unique regular expressions 

We aim to answer the following research questions:

\textbf{RQ1:} How frequently are regexes used in python projects?

To address this question, we measure how often  calls to the {\tt re module} are made per file and per project in Python projects. 


\textbf{RQ2:} How is the {\tt re module} used in python projects?

To address this research question, we measure the frequency of usage for calls to the {\tt re.compile} and {\tt re.search}, {\tt re.match}, {\tt re.split}, {\tt re.findall}, {\tt re.finditer}, {\tt re.sub}, {\tt re.subn} in Python projects scraped from GitHub. 


\textbf{RQ3:} Which regex language features are used most commonly in python?

Regex features are components of the regex language, such as capture groups, literals, and the kleene star. To measure feature usage, we use the X library, as described in Section~\ref{study:features}. 

\textbf{RQ4:} What is the impact of \emph{not} supporting various regex features on tool designers and users?

\todo{clean this up}
Use semantic analysis to illustrate the impact of missing features on a tool's applicability. Since our semantic analysis is based on Rex, we use syntactic analysis to observe the impact of not supporting various features on this, and other, research. 

%\textbf{RQ5:} What is the impact of \emph{not} supporting various regex features  on tool designers and users? 

We map the regex features to each of four research tools that are commonly used for regular expressions research. 
To address this research question, we looked at the most popular regular expression features that Rex does not support. As Rex is used for our semantic analysis in RQ4, we were interested in the impact of not supporting these features. 


\todo{need to justify why we chose the tools we did}



\subsection{Building the Corpus}
\label{study:corpus}
To build a large corpus of regular expressions strings for analysis, we turn to GitHub, a popular project hosting site containing over 100,000 Python projects. 
We used the GitHub api to page through all repositories, cloning projects that contain Python code. 
%, stopping when the scraper ran out of memory\footnote{\url{www.details.#better_parser}}. 
 For each project, we used Astroid[X] to build the AST of each Python file and find uses of Python's {\tt re} module.  Here is an example of one regex \emph{usage}, with key components labeled:

\begin{figure}[htb]
\centering
\includegraphics[width=\columnwidth]{../illustrations/exampleUsage.eps}
\caption{example of one regex usage}
\label{fig:exampleUsage}
\end{figure}

In the end, we scraped XYZ projects that contained at least some Python code. Of these, XYZ projects also contained at least one Python file with a regular expression, forming the final set of projects for our analysis. 

Within each relevant project, duplicate usages (same function, pattern and flags) within the same file (same relative path) were ignored. \todo{why were duplicates ignored?} Using git, each project was scanned at 20 evenly-spaced commits (or all commits if there were less than 20) in its history.  We observed and recorded \DTLfetch{data}{key}{nUsages}{value} regex usages in \DTLfetch{data}{key}{nProjScanned}{value} projects.

\subsection{Selecting Patterns}
Our analysis focuses on the patterns found, so we ignored the \DTLfetch{data}{key}{percentBadFlags}{value}\%  of usages using flags that can alter regex behavior.  An additional \DTLfetch{data}{key}{percentInvalidPattern}{value}\% of usages contained patterns that could not be compiled because the pattern was non-static (used some runtime variable), or because of other unknown parsing failures.

The remaining \DTLfetch{data}{key}{percentCleanUsages}{value}\% (\DTLfetch{data}{key}{nCleanUsages}{value}) usages were collapsed into \DTLfetch{data}{key}{nDistinctPatterns}{value} distinct pattern strings.  The resulting set of patten strings were parsed using an antlr-based, open source PCRE parser released by Bart Kiers\footnote{\url{https://github.com/bkiers/pcre-parser}}.  This parser was unable to support \DTLfetch{data}{key}{percentUnicode}{value}\% (\DTLfetch{data}{key}{N_UNICODE}{value}) of the patterns due to unsupported unicode characters.  Another \DTLfetch{data}{key}{percentAlien}{value}\% (\DTLfetch{data}{key}{N_ALIEN}{value}) of the patterns used regex features that we have chosen to exclude in this study\footnote{\url{www.details.#thistopic}}.  The \DTLfetch{data}{key}{nCorpus}{value} distinct pattern strings that remain were each assigned a weight value equal to the number of distinct projects the pattern appeared in.  We will refer to this set of weighted, distinct pattern strings as the \emph{collection}.

\subsection{Analyzing Features}
\label{study:features}

After picking four large regex research projects, the big table with the features was created in order to decide which unsupported features are used most often.  
Our semantic analysis is dependent on the use of Rex to generate strings so we can identify semantically related clusters. For three common features unsupported by Rex, we rely on syntactic analysis to determine similarity among regular expressions containing those features. For those features supported by Rex, we cluster the regular expressions based on semantic diversity. 

\subsubsection{Syntactic Diversity}
For the negative perspective, we picked three features: LZY, NCG, WNW that are unsupported by Rex and other projects.  For each of these features, we created a subset of the \emph{collection} where all the patterns contain that feature.  Then we used syntactic analysis...to create a similarity matrix.  We then used markov clustering [X] (MCL) to find clusters in the subset.  We used these clusters to assist our manual search for some common use cases for the unsupported feature.

\subsubsection{Semantic Diversity}
For the positive perspective, we created another subset of patterns (XYZ patterns) where Rex was able to generate strings that the pattern matched.  We then created a similarity graph with weighted, undirected edges as shown in Figure~\ref{fig:similarityConstruction}.

\begin{figure}
\begin{description}
\setlength{\parskip}{0pt} % block paragraphs
\setlength{\itemindent}{0in}
\item for each row i:
\setlength{\itemindent}{0.2in}
\item obtain set of Rex-generated strings Ri from pattern at index i
\item sRi = size of Ri
\item for each col j:
\setlength{\itemindent}{0.4in}
\item Nij = number of strings in Ri matched by pattern at index j
\item M[i][j] = Nij/sRi
\setlength{\itemindent}{0in}
\item G = empty graph
\item for each row i:
\setlength{\itemindent}{0.2in}
\item for each col j:
\setlength{\itemindent}{0.4in}
\item SIMij = (M[i][j]+M[j][i])/2
\item if SIMij > 0.75:
\setlength{\itemindent}{0.6in}
\item add edge (i,j)=SIMij to G
\setlength{\itemindent}{0in}
\setlength{\parskip}{10pt} % block paragraphs
\end{description}
\caption{Constructing Similarity Graph \label{fig:similarityConstruction}}
\end{figure}

Again we used MCL to find clusters that aided a manual search for use cases strongly associated with particular features.



%\subsubsection{Features}
%
%Here is a table showing all the features included in this study and which features are supported by four popular regex research projects/tools:

%\input{featuresAndProjectsTable}









