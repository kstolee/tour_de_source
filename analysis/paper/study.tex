\section{Study}
\subsection{\centerline{RECORDING REGEX USAGES}}

Fun fact: while creating similarity matrix, row 5464 took 2 hours, or almost 1 second per cell avg, only suffering 18 timeouts (1.2 secs).  What is this pesky pattern?

Using GHTorrent, we found the clone urls of \DTLfetch{data}{key}{nCloneURL}{value} github projects that had Python listed as the main language.  After consulting with github about the polite way to mine their service, we used 3 separate machines to clone projects in parallel.  On each machine, one attempt was made to clone each project into a unique directory.  \DTLfetch{data}{key}{nAborted}{value} of these attempts failed, so a total of \DTLfetch{data}{key}{nProjScanned}{value} projects were scanned overall.  For each of these projects, the java program launched a Python process that used `Astroid' to build the AST of each python file in the unique directory, recording uses of the `re' module.  Here is an example Python code using the `re' module:

Placeholder for several examples of useage of the `re' module...image?  Shows example of function, flags pattern.

TODO...mention rewinding, duplicate skipping, exact criteria for citing a usage...For each of the \DTLfetch{data}{key}{nUsages}{value} regex usages observed, we recorded which `re' function was used, what flags (if any) were used, and what pattern was found.

\subsection{\centerline{FILTERING REGEX USAGES}}
Because we want to let regex patterns alone define behavior later in our analysis, all regex usages where behavioral flags are used are discarded, along with all invalid pattern strings.   TODO - change to percents \DTLfetch{data}{key}{nBadFlags}{value} usages were discarded because they used behavior-altering flags, and \DTLfetch{data}{key}{nInvalidPattern}{value} without flags were discarded because their pattern strings were invalid (could not be compiled by Python into a regex object).

\DTLfetch{data}{key}{nCleanUsages}{value} regex usages remain (meow percent), which are then condensed to \DTLfetch{data}{key}{nDistinctPatterns}{value} distinct pattern strings.  The number of distinct pattern strings is much smaller because the same pattern string is often used in many distinct files and projects by different functions with different flags and these all count as separate usages.  The resulting set of patten strings were parsed using TODO - \footnote{\url{www.source}} PCRE parser.  \DTLfetch{data}{key}{percentPCREError}{value}\% of the strings caused the PCRE parser to raise an error.  Another \DTLfetch{data}{key}{percentAlien}{value}\% used regex features that we have chosen to exclude in this study (most notably named capturing groups).  The \DTLfetch{data}{key}{nCorpus}{value} distinct pattern strings that remain are given a weight based upon how many projects the pattern appeared in (FYI no forked projects were scanned).

TODO - clean this: So then we use the following 4? techniques to try and best represent the entire corpus using a few regexes: 1. weight (frequency of usage across projects) 2. features (matching properties of feature usage) 3. syntactic clustering 4. semantic clustering ...and also we give the topN clones by weight, and a list that tries to include information from all 4 lists?  That will be all.  Future work: mine more projects and compare that result with this result.  Compare across languages (java, javascript,ruby,etc.).

TODO - list research questions (metrics and how they are computed?)

RQ1: How is the {\tt re module} used in python projects?
RQ2: How frequently are regexes used in python projects?
RQ3: Which regex language features are used most commonly in python?
RQ4: How syntactically diverse are regexes used in python?
RQ5: How semangically diverse are regexes used in python?

\subsubsection{\centerline{FEATURES}}

Here is a table showing all the features included in this study and which features are supported by four popular regex research projects/tools:

%\input{featuresAndProjectsTable}





